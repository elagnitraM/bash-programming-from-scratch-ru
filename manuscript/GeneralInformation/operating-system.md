## Операционные системы

### Предпосылки возникновения ОС

Большинство пользователей компьютера понимает, зачем нужна [**операционная система**](https://ru.wikipedia.org/wiki/Операционная_система#Функции) (ОС). Как правило, при покупке или скачивании какого-то приложения вы обращаете внимание на его системные требования. В одном из пунктов этих требований указана необходимая ОС. Получается, что ОС — это некоторая программная платформа, которая нужна для работы приложений. Но откуда взялось это требование? Почему нельзя просто купить компьютер и запустить на нём приложение без всякой ОС?

Эти вопросы кажутся бессмысленными только на первый взгляд. Подумайте сами: современные ОС ввиду своей универсальности имеют множество функций. Большая их часть каждому конкретному пользователю просто не нужна. Но несмотря на это, для обслуживания этих функций ОС активно использует ресурсы компьютера. В результате для полезной нагрузки системы, то есть приложений которые пользователь хочет запустить, ресурсов остаётся намного меньше. Это приводит к медленной работе, зависаниям и даже перезагрузкам компьютера.

Обратимся к истории, чтобы выяснить причины возникновения ОС. На самом деле первая ОС [GM-NAA I/O](https://ru.wikipedia.org/wiki/GM-NAA_I/O) появилась только в 1956 году для компьютера [IBM 704](https://ru.wikipedia.org/wiki/IBM_704). Все более ранние модели компьютеров обходились без ОС. Почему в этом не возникало необходимости?

Основная причина заключается в быстродействии. Например, рассмотрим первый [**электромеханический компьютер**](http://chernykh.net/content/view/16/40/), сконструированный [Германом Холлеритом](https://ru.wikipedia.org/wiki/Холлерит,_Герман) в 1890 году. Этот компьютер, получивший название табулятор, не требовал не только ОС, но и программ в современном смысле этого слова. Табулятор мог выполнять только ограниченный набор арифметических операций, который определялся его конструкцией. Данные для вычислений загружались с [**перфокарт**](https://ru.wikipedia.org/wiki/Перфокарта), которые представляли собой листки плотной бумаги с пробитыми отверстиями. Эти листки вручную подготавливались и укладывались в специальные приёмные устройства. Там они нанизывались на иглы и в местах отверстий происходило замыкание электрической цепи. Каждое замыкание приводило к увеличению механического счётчика, представлявшего собой вращающийся цилиндр. Результаты вычислений выводились на циферблаты, напоминавшие часы.

Иллюстрация 1-1 демонстрирует табулятор, построенный Германом Холлеритом.

{caption: "Иллюстрация 1-1. Табулятор Холлерита", height: "30%"}
![Табулятор Холлерита](images/GeneralInformation/tabulating-machine.jpg)

По современным меркам табулятор работал очень медленно. На это было несколько причин. Прежде всего данные для вычислений подготавливались вручную. Не существовало способа автоматически пробивать перфокарты. Далее загрузка перфокарт в компьютер также выполнялась вручную. Сам табулятор содержал большое количество механических частей: иглы для считывания данных, счётчик из вращающихся цилиндров, циферблаты для вывода данных. Вся эта механика работала очень медленно, во временных интервалах порядка секунды. Никакая автоматизация не могла бы помочь ускорить эти процессы.

На смену табуляторам, работающим на вращающихся цилиндрах, пришли компьютеры, использующие [**реле**](https://ru.wikipedia.org/wiki/Реле). Реле — это механический элемент, который меняет своё состояние под воздействием электрического тока. Один из [первых релейных компьютеров](https://habr.com/ru/company/ua-hosting/blog/386247), называвшийся Z2, был сконструирован немецким инженером [Конрадом Цузе](https://ru.wikipedia.org/wiki/Цузе,_Конрад) в 1939 году. Затем компьютер был усовершенствован в 1941 году и получил название Z3. Переход на реле позволил сократить время на выполнение каждой элементарной операции с секунд до миллисекунд.

Кроме возросшей скорости вычислений, компьютеры Цузе отличала ещё одна особенность. В них появилось понятие программы. Теперь с помощью перфокарт вводились не исходные данные задачи, а алгоритмы по которым надо выполнить её решение. Для ввода данных использовалась клавиатура, отдалённо напоминающая печатную машинку.

Появление [**программируемых компьютеров**](https://ru.wikipedia.org/wiki/Компьютер_общего_назначения) (также известных как универсальные) стало важной вехой в развитии вычислительной техники. До этого момента машины были способны выполнять только узкоспециализированные задачи. Это было слишком дорого, неэффективно и останавливало многих потенциальных инвесторов. Заказчиками первых крупных проектов по конструированию компьютеров были военные в годы Второй мировой войны.

Следующим важным шагом стало создание компьютера [**ENIAC**](https://ru.wikipedia.org/wiki/ЭНИАК) (см. иллюстрацию 1-2) в 1946 году [Джоном Эккертом](https://ru.wikipedia.org/wiki/Эккерт,_Джон_Преспер) и [Джоном Мокли](https://ru.wikipedia.org/wiki/Мокли,_Джон). В качестве рабочих элементов в нём использовались не реле, а [электровакуумные лампы](https://ru.wikipedia.org/wiki/Электронная_лампа). То есть электромеханические компоненты с большим временем отклика были заменены на чисто электронные. Это позволило на порядок увеличить быстродействие компьютера и добиться выполнения одной элементарной операции за 200 микросекунд.

{caption: "Иллюстрация 1-2. ENIAC", height: "30%"}
![ENIAC](images/GeneralInformation/eniac.jpg)

В среде инженеров долго сохранялось скептическое отношение к электровакуумным лампам. Они были известны своей низкой надёжностью и высоким энергопотреблением. Никто не верил, что сконструированная на них машина вообще сможет работать. В ENIAC использовалось 18 000 ламп. Они часто выходили из строя, но между отказами компьютер успешно справлялся с вычислениями. Это стало успешным примером использования ламп, которое переубедило многих конструкторов. 

ENIAC был программируемым компьютером. В нём алгоритм вычислений задавался с помощью комбинации переключателей и перемычек на коммутационных панелях. Это требовало значительного времени и одновременной работы нескольких человек. На иллюстрации 1-3 изображена одна из панелей для программирования ENIAC.

{caption: "Иллюстрация 1-3. Панель программирования ENIAC", height: "30%"}
![Панель программирования ENIAC](images/GeneralInformation/eniac-programming.jpg)

Для ввода исходных данных и вывода результатов использовались перфокарты, как и в предыдущих моделях компьютеров. Иногда перфокарты использовались для хранения промежуточных рассчётов. Если исходная задача из-за своей сложности  не могла быть решена сразу, она разбивалась на несколько подзадач. После выполнения каждой из них результаты выгружались на перфокартах, а компьютер перепрограммировался. Затем перфокарты загружались обратно в качестве входных данных.

Опыт эксплуатации ENIAC показал, что главным ограничением производительности являются все механические операции: ручное перепрограммирование с помощью переключателей и перемычек, чтение и пробивание перфокарт. Несмотря на то, что сам компьютер обладал небывалой по тем временам производительность, для решения конкретной задачи на нём требовалось значительное время. Большую часть этого времени компьютер простаивал, ожидая программы или входных данных. Поэтому дальнейшее развитие компьютеров привело к появлению более совершенных средств ввода данных и программ, а также вывода результатов вычислений.

После изобретения [**транзисторов**](https://ru.wikipedia.org/wiki/Транзистор) и начала применения их в компьютерах, вычислительная мощность последних увеличилась на порядок. Вместе с более совершенными средствами ввода-вывода это привело к их более интенсивной эксплуатации и частому перепрограммированию. За счёт широкого распространения компьютеров не только в военных, но и в коммерческих проектах возросло число и разнообразие программ.

Часто программы должны были исполняться друг за другом без задержек, чтобы избежать простоя оборудования. Для автоматизации загрузки программ и вывода их результатов потребовались специальные решения. Именно для управления выполнением программ и была разработана первая ОС GM-NAA I/O.

Возросшее количество программ создало не только потребность в организации их непрерывного исполнения. Дело в том, что загруженная программа должна была определять все требуемые от компьютера функции. Например, она включала в себя код для управления устройствами ввода-вывода и другим оборудованием. Поскольку для конкретной модели компьютера это оборудование оставалось неизменным, код для его поддержки дублировался. Он кочевал из одной программы в другую, занимая лишнее место место на устройствах хранения. Со временем его стали выносить в отдельную служебную программу, которая загружалась вместе с основной. Затем эти служебные программы вошли в состав первых ОС.

Вернёмся к нашему вопросу о необходимости операционных систем. История показывает, что они совершенно необязательны для запуска приложений. Программы, работающие без ОС, есть и сегодня. Например, это [**утилиты**](https://ru.wikipedia.org/wiki/Утилита) проверки памяти и разбивки диска, а также некоторые антивирусы. Однако, разработка таких программ требует больше времени и сил. В них приходится включать код для поддержки оборудования, который обычно предоставляется ОС. Поэтому большинство приложений активно использует возможности ОС.

### Возможности ОС

Почему мы начали изучение программирования с рассмотрения ОС? Иллюстрация 1-3 демонстрирует схему взаимодействия ОС с [**прикладными программами**](https://ru.wikipedia.org/wiki/Прикладное_программное_обеспечение) и [**аппаратным обеспечением**](https://ru.wikipedia.org/wiki/Аппаратное_обеспечение).

{caption: "Иллюстрация 1-3. Схема взаимодействия ОС с программами и аппаратным обеспечением", height: "50%"}
![Схема взаимодействия ОС](images/GeneralInformation/operating-system.png)

Из этой схемы становится понятно, что разработчики прикладных приложений, как правило, пользуются функциями и [**интерфейсом**](https://ru.wikipedia.org/wiki/API) ОС для доступа к аппаратным ресурсам. Именно ОС служит платформой, на которой будет выполняться ваша программа.

Итак, мы выяснили, что ОС необязательна. Однако, она позволяет быстрее и эффективнее разрабатывать программы. За счёт чего это происходит?

Прототипом ОС стал повторяющийся в разных приложениях код, который выносился в отдельные служебные программы. В дальнейшем этот код развивался, в него добавлялись новые функции. В результате разработчики ОС выполнили большую часть работы, которую в противном случае пришлось бы делать программистам прикладных приложений. Разберёмся подробнее в том, какие функции предоставляет ОС.

Всё аппаратное обеспечение компьютера, т.е. его электронные и механические части, можно рассматривать как некоторые ресурсы для вычислений. Программы так или иначе пользуются ими в своих алгоритмах. Но для доступа к каждому виду ресурсов приходится следовать определённым правилам. Например, две программы не могут одновременно писать данные на [жёсткий диск](https://ru.wikipedia.org/wiki/Жёсткий_диск#Технологии_записи_данных) в одну и ту же область. Во-первых, запись осуществляется единственной магнитной головкой жёсткого диска. Во-вторых, данные, записанные первым приложением, будут затёрты данными второго. Поэтому одновременные запросы программ на запись должны блокироваться или помещаться в очередь и исполняться друг за другом. За эти механизмы отвечает ОС, а точнее её [**ядро**](https://ru.wikipedia.org/wiki/Ядро_операционной_системы) (см. иллюстрацию 1-3), в котором реализована [**файловая система**](https://ru.wikipedia.org/wiki/Файловая_система). Похожим образом организуется доступ ко всем [**периферийным**](https://ru.wikipedia.org/wiki/Периферийное_устройство) и внутренним устройствам компьютера. Этот доступ осуществляется через специальные программы, называемые [**драйверами устройств**](https://ru.wikipedia.org/wiki/Драйвер) (см. иллюстрацию 1-3).

Что такое периферийные устройства, и чем они отличаются от внутренних? К периферийным относятся все устройства, отвечающие за ввод и вывод информации, а также её постоянное хранение. Например, клавиатура, мышь, микрофон, монитор, колонки, жёсткий диск. Внутренние устройства отвечают за обработку информации, то есть непосредственное исполнение программ. К ним относят [**центральный процессор**](https://ru.wikipedia.org/wiki/Центральный_процессор) (central processing unit, CPU), [**оперативную память**](https://ru.wikipedia.org/wiki/Оперативная_память) (random-access memory, RAM), [**видеокарту**](https://ru.wikipedia.org/wiki/Видеокарта) (graphics processing unit, GPU).

Доступ к аппаратным ресурсам — это не единственное, что предоставляет ОС. Кроме них есть программные ресурсы самой ОС. Это тот самый повторяющийся код, ставший со временем служебными программами и оформленный в [**системные библиотеки**](https://ru.wikipedia.org/wiki/Библиотека_(программирование)) (см. иллюстрацию 1-3). Например, компонент Windows под названием [**интерфейс графических устройств**](https://ru.wikipedia.org/wiki/GDI) позволяет приложениям манипулировать графическими объектами. С их помощью разработчики могут создавать графический интерфейс для своих программ. К этому типу ресурсов можно отнести все приложения и компоненты ОС, установленные на компьютере. Кроме собственных программ ОС может предоставлять доступ и к алгоритмам сторонних приложений или библиотек.

Кроме управления ресурсами, ОС организует работу запущенных приложений. Прежде всего код приложения должен быть загружен с [**устройства хранения информации**](https://ru.wikipedia.org/wiki/Компьютерная_память) (будь то перфокарта или жёсткий диск) и помещён в оперативную память компьютера. Эта процедура нетривиальная, поскольку требуется также загрузить код всех сторонних библиотек, которые нужны приложению для работы. Процесс запуска и исполнения программы мы рассмотрим подробнее в следующем разделе.

Если ОС многопользовательская, она берёт на себя функции контроля доступа к данным. Таким образом каждый пользователь может работать только со своими собственными файлами и каталогами.

Подведём итог. ОС выполняет следующие функции:

1. Предоставляет доступ к аппаратным ресурсам компьютера.

2. Предоставляет программные ресурсы в виде системных библиотек.

3. Осуществляет запуск приложений.

4. Организует взаимодействие приложений друг с другом.

5. Контролирует доступ пользователей к своим данным.

Изучив эти функции, внимательный читатель возможно догадался, что без ОС невозможно одновременное выполнение нескольких приложений. Ведь их разработчики не могут предусмотреть в каком сочетании программы будут выполняться. Только ОС имеет достаточно информации, чтобы эффективно распределить ресурсы компьютера в реальном времени.

### Современные ОС

Мы рассмотрели ОС в общих чертах. Теперь с учётом наших новых знаний поговорим о современных ОС. Они отличаются друг от друга не столько предоставляемыми функциями, которые у всех почти одинаковы, сколько способами их реализации. Эти особенности реализации и решения, которые к ним привели, принято называть [**архитектурой**](https://ru.wikipedia.org/wiki/Архитектура_программного_обеспечения).

#### Многозадачность

Прежде всего отметим, что все современные ОС [**многозадачные**](https://ru.wikipedia.org/wiki/Многозадачность). Это значит, что они поддерживают одновременное исполнение нескольких программ. Почему так получилось?

Первые многозадачные ОС появились задолго до привычных нам [персональных компьютеров](https://ru.wikipedia.org/wiki/Персональный_компьютер#История). В 1960-х годах они работали на [мэйнфреймах](https://ru.wikipedia.org/wiki/Мейнфрейм) и решали задачу эффективного использования вычислительного времени. Мэйнфрейм — это большой универсальный компьютер. Как правило, он стоил дорого и очень интенсивно использовался для расчётов. Рост производительности мэйнфреймов привёл к тому, что вычисления стали выполняться намного быстрее чем операции ввода и вывода. Например, время необходимое принтеру для распечатки результатов хватило бы для решения следующей задачи. Эта проблема простоя оборудования привела к идее многозадачности. 

Актуальность многозадачности для высокопроизводительных мэйнфреймов очевидна. Но почему она не менее важна для персональных компьютеров?

ОС, которые использовались на первых персональных компьютерах (ПК), были однозадачными. Такое решение оказалось приемлемо, поскольку их производительность была значительно ниже чем у мэйнфреймов. ПК не выполняли интенсивных вычислений и были относительно недорогими. Даже если какая-то задача требовала больше времени, чем обычно, пользователи могли подождать. Возможно, некоторые читатели в прошлом работали с [MS-DOS](https://ru.wikipedia.org/wiki/MS-DOS). Это пример типичной однозадачной ОС.

Иллюстрация 1-4 демонстрирует первый получивший массовое распространение персональный компьютер IBM 5150.

{caption: "Иллюстрация 1-4. Персональный компьютер IBM 5150", height: "30%"}
![IBM 5151](images/GeneralInformation/ibm-pc.jpg)

Однако, увеличение мощности персональных компьютеров привело к значительному простою центрального процессора. Почему это произошло? Опять же дело в операциях ввода-вывода данных.

Представьте, что вы работаете над электронной таблицей. Например, заносите список сотрудников вашей компании и их контактные данные. Как бы быстро вы не печатали текст, между нажатиями клавиш проходят миллисекунды. По компьютерным масштабам это огромные промежутки времени, за которые процессор может успеть обработать немало информации. Теперь представьте, что вы забыли чей-то номер и уточняете его у кого-то. Теперь счёт пошёл на секунды и минуты. За это время современный процессор мог бы обработать бухгалтерский отчёт небольшой фирмы. Мы рассмотрели только задержки ввода информации, но то же самое происходит и с выводом. Представьте, что на экран вывелось сообщение об ошибке. Несколько сотен миллисекунд у вас уйдёт только на то, чтобы понять, что произошло. Затем вы читаете сообщение. Думаю, вы уже поняли основную идею: в масштабах компьютерного времени пользователь очень медленно реагирует на события.

Чтобы процессор не простаивал, ОС может остановить выполнение приложения, ожидающего действия от пользователя, и предоставить аппаратные ресурсы другой программе, работающей параллельно. Именно в этом заключается суть многозадачности.

Существует несколько способов реализации многозадачности. В современных ОС применяется [**вытесняющая многозадачность**](https://ru.wikipedia.org/wiki/Вытесняющая_многозадачность) с псевдопараллельной обработкой задач. Это означает, что ОС самостоятельно принимает решение о том, какая задача будет выполняться в данный момент времени. При этом выборе учитываются приоритеты задач. То есть более приоритетные будут получать аппаратные ресурсы чаще, чем низкоприоритетные. Механизм переключения задач реализован в ядре ОС и называется [**планировщиком задач**](https://ru.wikipedia.org/wiki/Диспетчер_операционной_системы).

Псевдопараллельность обработки означает, что в каждый момент времени выполняется одна-единственная задача. Это справедливо для процессоров с одним [ядром](https://ru.wikipedia.org/wiki/Ядро_микропроцессора). Современные процессоры обычно имеют несколько ядер. Поэтому число одновременно выполняемых задач, грубо говоря, равно числу ядер. Но принцип вытесняющей многозадачности с постоянным переключением задач сохраняется.

#### Интерфейс пользователя

Ещё одна общая черта современных ОС для персональных компьютеров и ноутбуков — это наличие [**графического интерфейса пользователя**](https://ru.wikipedia.org/wiki/Графический_интерфейс_пользователя) (graphical user interface, GUI). Благодаря ему пользователь может выбрать задачи или программы для запуска, а также манипулировать ресурсами, предоставляемыми ОС (например, файловой системой). Пример графического интерфейса ОС Windows приведён на иллюстрации 1-5. На ней вы видите скриншот рабочего стола и окна трёх одновременно работающих приложений: Проводника, Блокнота и Калькулятора.

{caption: "Иллюстрация 1-5. Графический интерфейс пользователя"}
![Графический интерфейс пользователя](images/GeneralInformation/gui.png)

Сегодня графический интерфейс кажется неотъемлемой частью ОС, но на самом деле он появился относительно недавно. На первых программируемых компьютерах для ввода и вывода информации использовались перфокарты и магнитные ленты. Таким образом пользователь загружал код программы и её исходные данные. После окончания работы, результаты печатались на принтере. Обслуживание такого интерфейса требовало минимум вычислительных ресурсов. Поэтому он хорошо подходил для маломощных компьютеров того времени.

С увеличением производительности компьютеров и устройств ввода-вывода появилась возможность интерактивного взаимодействия с пользователем в реальном времени. Возник [**интерфейс командной строки**](https://ru.wikipedia.org/wiki/Интерфейс_командной_строки) (command-line interface, CLI). Он позволяет вводить текстовые команды и выводить результат их исполнения на монитор. Основная проблема такого интерфейса заключается в сложности освоения. Список всех доступных команд, как правило, достаточно большой. При этом каждая из них имеет различные входные параметры. Чтобы запомнить хотя бы наиболее часто используемые команды, надо потратить немало времени. Пример интерфейса командной строки приведён на иллюстрации 1-6. На ней вы видите окно интерпретатора Bash и вывод утилит `ping` и `ls`.

{caption: "Иллюстрация 1-6. Интерфейс командной строки", height: "50%"}
![Интерфейс командной строки](images/GeneralInformation/cli.png)

Попытки решить проблему с наглядным представлением доступных команд привели к созданию [**текстового интерфейса пользователя**](https://ru.wikipedia.org/wiki/Текстовый_интерфейс_пользователя). В нём наряду с буквенными и цифровыми символами используется [**псевдографика**](https://ru.wikipedia.org/wiki/Псевдографика). Под псевдографикой подразумеваются специальные символы, отображающие графические примитивы (например, линии, прямоугольники, треугольники и т.д.). Пример текстового интерфейса пользователя приведён на иллюстрации 1-7. Это программа `htop` для просмотра системных ресурсов.

{caption: "Иллюстрация 1-7. Текстовый интерфейс пользователя", height: "50%"}
![Текстовый интерфейс пользователя](images/GeneralInformation/tui.png)

Только благодаря дальнейшему увеличению вычислительной мощности компьютеров, стало возможно заменить нетребовательные к ресурсам командную строку и текстовый интерфейс на хорошо знакомый нам графический.

#### Семейства ОС

Сегодня на рынке персональных компьютеров доминируют три основных семейства ОС:

* [Windows](https://ru.wikipedia.org/wiki/Windows)
* [Linux](https://ru.wikipedia.org/wiki/Linux)
* [macOS](https://ru.wikipedia.org/wiki/MacOS)

Может возникнуть вопрос: что именно подразумевается под семейством ОС? Этот термин означает ряд версий ОС, которые следуют одним и тем же архитектурным решениям, а также наследуют некоторые особенности реализации тех или иных функций.

Почему же разработчики каждой ОС предпочитают придерживаться одной и той же архитектуры, а не предлагают что-то принципиально новое в следующих версиях? На самом деле изменения в современных ОС происходят, но очень постепенно и медленно. Причина этого в так называемой [**обратной совместимости**](https://ru.wikipedia.org/wiki/Обратная_совместимость). Эта совместимость предполагает наличие некоторых старых функций в новой версии ОС. Они нужны для корректной работы написанных ранее программ. На первый взгляд это требование может показаться совершенно неважным. Но на самом деле это серьёзное ограничение при разработке программного обеспечения. Давайте разберёмся, почему.

Представьте, что вы разработали программу для ОС Windows и продаёте её. Иногда в ней обнаруживаются ошибки, которые вы успешно исправляете. Время от времени вы добавляете в неё новые функции. Теперь представьте, что выходит новая версия Windows, на которой ваша программа перестаёт работать. У пользователей есть два решения: ждать от вас новой версии программы или отказаться от перехода на новую версию Windows. Теперь предположим, что новая версия ОС принципиально отличается от предыдущей. Это значит, что вам придётся переписать вашу программу буквально с нуля. Посчитайте всё время, которое вы уже потратили на исправление ошибок и добавление новых функций. Эту работу в полном объёме придётся повторить. Скорее всего вы откажетесь от этой идеи и предложите пользователям оставаться на старой версии Windows. Теперь представьте, что таких программ как ваша очень много. Их разработчики придут к тому же решению, что и вы. В результате новая версия Windows окажется никому не нужна. В этом и заключается проблема обратной совместимости. Именно поэтому и существуют семейства ОС.

Влияние приложений, доступных под конкретную ОС, сложно переоценить. Например, успех ОС Windows и персональных компьютеров от IBM во многом обусловлен табличным процессором [Lotus 1-2-3](https://ru.wikipedia.org/wiki/Lotus_1-2-3). Он был так называемым [killer application](https://ru.wikipedia.org/wiki/Killer_application) (убойное приложение), ради запуска которого пользователи были готовы покупать и IBM PC, и Windows. Аналогично табличный процессор [VisiCalc](https://ru.wikipedia.org/wiki/VisiCalc) способствовал распространению компьютеров [Apple II](https://ru.wikipedia.org/wiki/Apple_II), а бесплатные компиляторы языков C, Fortran и Pascal подогрели интерес к Unix в университетских кругах. За каждой из трёх ОС, доминирующих сегодня, стоит какое-то killer application. Далее их распространению способствовал [сетевой эффект](https://ru.wikipedia.org/wiki/Сетевой_эффект), когда разработчики программ выбирали в качестве целевой платформы именно ту ОС, которая уже была установлена у большинства пользователей.

Вернёмся к нашему списку семейств ОС. Windows и Linux примечательны тем, что не привязаны к конкретной аппаратной платформе. Это значит, что купив любой персональный компьютер или ноутбук, вы без особых трудностей сможете установить на него эти ОС. macOS в отличие от них рассчитана на запуск только на устройствах от Apple. Чтобы установить macOS на чём-то другом, вам потребуются её неофициальная [модифицированная версия](https://ru.wikipedia.org/wiki/OSx86). Совместимость с аппаратной платформой — это хороший пример одного из архитектурных решений. Но таких решений много, и все вместе они формируют особенности каждого семейства.

Неудивительно, что ОС во многом определяет инфраструктуру, доступную программисту. Она диктует не только инструменты разработки, такие как IDE, компилятор, система сборки, но и некоторые архитектурные решения самих запускаемых на ней приложений. Можно говорить о некоторой сложившейся культуре написания программ под конкретную ОС. Это очень важный момент, который следует всегда учитывать: под разные ОС программы принято разрабатывать по-разному.

Рассмотрим различие этих культур подробнее на примере Windows и Linux.

#### Windows

Как вам известно, Windows — это [проприетарная](https://ru.wikipedia.org/wiki/Проприетарное_программное_обеспечение) ОС. Это означает, что все её исходные коды закрыты для постороннего изучения и модификации. Вы не сможете законным способом узнать о ней больше, чем разработчики посчитают нужным вам сообщить. Чтобы установить Windows на свой компьютер, вам надо купить её у компании Microsoft. Однако, в большинстве случаев эта ОС уже предустановлена на новые компьютеры и ноутбуки, а её цена включена в стоимость устройства.

Обратите внимание, что целевой платформой Windows были и остаются относительно дешёвые персональные компьютеры. Многие могут позволить себе купить такое устройство. Следовательно, рынок потенциальных пользователей огромен. Microsoft стремится всеми силами сохранить конкурентное преимущество на этом рынке. Компания опасается появления аналогов своей ОС с аналогичными же возможностями. Именно поэтому Microsoft заботится о защите своей интеллектуальной собственности не только техническими, но и юридическими путями. Строго говоря, пользовательское соглашение запрещает вам исследовать внутреннее устройство ОС.

За всё время существования семейства ОС Windows под него было написано очень много программ. Первые из них (например, пакет офисных приложений [Microsoft Office](https://ru.wikipedia.org/wiki/Microsoft_Office) или [стандартные приложения Windows](https://ru.wikipedia.org/wiki/Категория:Стандартные_приложения_Windows)) создавались самой компанией Microsoft. Для сторонних разработчиков они послужили в некотором роде образцом того, как следует писать программы под эту платформу. Очевидно, что Microsoft при разработке своих приложений придерживалась того же принципа закрытости, что и при разработке ОС: исходные коды недоступны конечным пользователям, форматы данных недокументированны, сторонние утилиты не могут получить доступа к возможностям приложений. Опять же все эти решения были продиктованы заботой о защите интеллектуальной собственности компании от конкурентов.

Сторонние разработчики программ последовали примеру Microsoft и зачастую стали придерживаться той же философии закрытости. Большинство получившихся приложений самодостаточны и независимы друг от друга. Форматы их данных, как правило, закодированы и недокументированны.

Если вы опытный пользователь компьютера, вы легко сможете представить себе типичное Windows приложение. Оно представляет собой окно с такими [элементами интерфейса](https://ru.wikipedia.org/wiki/Элемент_интерфейса), как кнопки, поля ввода, вкладки и т.д. Через этот интерфейс пользователь манипулирует каким-то данными (например, текстом, изображением, звуковой записью и т.д.). Результат работы сохраняется на жёсткий диск компьютера и может быть повторно загружен в том же самом приложении. Очень велика вероятность, что если вы напишете собственную Windows-программу, она будет работать похожим образом. Именно такая преемственность решений и имеется ввиду, когда мы говорим о сложившейся культуре разработки под конкретную ОС.

#### Linux

Linux является идейным наследником ОС [Unix](https://ru.wikipedia.org/wiki/Unix) и следует её [**спецификациям**](https://ru.wikipedia.org/wiki/Спецификация). Спецификация — это документ с требованиями к системе, который также определяет её поведение и устройство. Получается, что Linux заимствовал многие идеи и решения Unix, что в результате привело к похожему поведению.

{caption: "Иллюстрация 1-8. Мэйнфрейм модели GE-645", height: "30%"}
![Мэйнфрейм модели GE-645](images/GeneralInformation/ge-645.jpg)

Сама Unix возникла в конце 1960-х годов. Она разрабатывалась как хобби-проект двумя инженерами компании Bell Labs: [Кеном Томпсоном](https://ru.wikipedia.org/wiki/Томпсон,_Кен) и [Деннисом Ритчи](https://ru.wikipedia.org/wiki/Ритчи,_Деннис). Всё началось с того, что Кен написал компьютерную игру [Space Travel](https://ru.wikipedia.org/wiki/Space_Travel). Она запускалась на мэйнфреймах модели GE-645 (см. иллюстрацию 1-8) от компании General Electric, работающих под управлением ОС GECOS. Эти компьютеры представляли собой шкафы с электроникой и стоили порядка 7 500 000$. Их вычислительные ресурсы активно использовались для нужд компании и были постоянно заняты. Поэтому Кен решил портировать свою игру на относительно недорогой и реже используемый коллегами [мини-компьютер](https://en.wikipedia.org/wiki/Minicomputer) [PDP-7](https://ru.wikipedia.org/wiki/PDP-7) (см. иллюстрацию 1-9) стоимостью порядка 72 000$. Проблема была в том, что игра использовала возможности ОС GECOS, которые были недоступны на PDP-7. Поэтому Кену и присоединившемуся к нему Деннису пришлось реализовать несколько библиотек и систем, которые впоследствии развились в Unix.

{caption: "Иллюстрация 1-9. Мини-компьютер PDP-7", height: "30%"}
![Мини-компьютер PDP-7](images/GeneralInformation/pdp-7.jpg)

Очевидно, в своём проекте разработчики Unix не заботились о защите интеллектуальной собственности, поскольку не собирались продавать свою ОС. Она разрабатывалась для собственных нужд и распространялась с открытым исходным кодом, доступным для изучения и модификации любым желающим. Изначально круг пользователей ограничивался сотрудниками компании Bell Labs. Позднее AT&T, которой принадлежала Bell Labs, предоставила исходный код Unix высшим учебным заведениям США. Таким образом развитие ОС продолжилось в университетских кругах.

Linux была создана в 1991 году [Линусом Торвальдсом](https://ru.wikipedia.org/wiki/Торвальдс,_Линус) во время его обучения в Хельсинкском университете. Линус решал чисто практическую проблему: в то время персональные компьютеры не имели полноценной Unix-совместимой ОС. В университете студенты выполняли учебные задания на миникомпьютере MicroVAX под управлением Unix, но дома у них не было оборудования, подходящего для её запуска. Единственной альтернативой Unix была ОС [Minix](https://ru.wikipedia.org/wiki/Minix), разработанная Эндрю Таненбаумом в 1987 году для персональных компьютеров IBM с процессорами Intel 80268. Но эта ОС разрабатывалась для учебных целей, и поэтому Эндрю отказывался вносить в неё изменения для поддержки более современных компьютеров. Эти изменения неизбежно привели бы к усложнению системы и сделали бы её непригодной для обучения студентов.

Линус задался целью написать Unix-совместимую ОС для своего нового компьютера IBM с процессором Intel 80386. Её прототипом стала учебная ОС Minix. Как и у создателей Unix, у него не было коммерческих интересов, связанных с продажей результата своего труда. Он разрабатывал систему для собственных нужд. Поэтому его ОС стала бесплатной и свободно распространялась с исходным кодом через интернет.

На самом деле Linux — это не более чем ядро ОС, предоставляющее функции для работы с памятью, файловой системой, периферийными устройствами, а также управлением процессорным временем. Большинство функций системы были доступны через свободные [пользовательские компоненты GNU](https://ru.wikipedia.org/wiki/Проект_GNU), которые Линус включил в [дистрибутив](https://ru.wikipedia.org/wiki/Дистрибутив_Linux) своей ОС.

Изначально у Linux, как у и Unix, не было графической подсистемы. Все приложения пользователь запускал из командной строки. Только некоторые сложные приложения имели текстовый интерфейс. Со временем в Linux появилась оконная система [X Window System](https://ru.wikipedia.org/wiki/X_Window_System), а вместе с ней и приложения с графическим интерфейсом, более привычные пользователям Windows.

Инфраструктура, в которой возник и развивался Linux, во многом определила культуру написания приложений. В ней предпочтение отдаётся узкоспециализированным утилитам командной строки, которые выполняют одну конкретную задачу. Результат работы таких утилит доступен для распространения через открытый формат данных (как правило [текстовый](https://ru.wikipedia.org/wiki/Текстовые_данные)). Исходный код самих утилит всегда доступен для модификации.

Культура Linux значительно отличается от стандартов разработки, принятых в Windows. В Windows каждое приложение монолитно и самостоятельно выполняет все необходимые для своей работы задачи. Оно не полагается на сторонние утилиты, которые могут оказаться платными или недоступными для пользователя по какой-то причине. Разработчик должен рассчитывать только на себя. Он не может требовать от пользователя купить что-то дополнительное для работы своего приложения. В Linux же подавляющее большинство утилит бесплатны, взаимозаменяемы и легко доступны через Интернет. Поэтому вполне естественно, что какое-то приложение потребует загрузить и установить недостающие ему системные компоненты или другое приложение.

Даже монолитные графические приложения в Linux очень часто имеют дополнительный интерфейс командной строки. Таким образом они органично вписываются в экосистему и легко интегрируются с другими утилитами и приложениями.

Когда сложный вычислительный процесс строится на использовании набора отдельных узкоспециализированных приложений, становится насущным вопрос написания сценариев, по которому они должны выполняться. Именно для этой задачи была создана [командная оболочка](https://ru.wikipedia.org/wiki/Командная_оболочка_Unix) [Bourne shell](https://ru.wikipedia.org/wiki/Bourne_shell) и её потомок [Bash](https://ru.wikipedia.org/wiki/Bash). В этой книге мы будем работать именно с Bash.

I> Подробнее о культуре разработки в Unix вы можете узнать из книги [Эрика Реймонда "Искусство программирования в Unix"](https://ru.wikipedia.org/wiki/Философия_Unix#Реймонд:_Искусство_программирования_в_Unix).